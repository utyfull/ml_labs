{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120385,"databundleVersionId":14411012,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.127992Z","iopub.execute_input":"2025-12-04T10:47:34.128231Z","iopub.status.idle":"2025-12-04T10:47:34.135403Z","shell.execute_reply.started":"2025-12-04T10:47:34.128217Z","shell.execute_reply":"2025-12-04T10:47:34.134300Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mai-ml-lab-2-308/test_c.csv\n/kaggle/input/mai-ml-lab-2-308/train_c.csv\n/kaggle/input/mai-ml-lab-2-308/ex_c.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom itertools import combinations\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\ntrain_csv = \"/kaggle/input/mai-ml-lab-2-308/train_c.csv\"\ntest_csv  = \"/kaggle/input/mai-ml-lab-2-308/test_c.csv\"\n\nabs_cap = 1000.0\ntop_k = 8\ndegree = 4\nalpha = 6\nclip_val = 10.0\neps = 1e-6\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.136964Z","iopub.execute_input":"2025-12-04T10:47:34.137204Z","iopub.status.idle":"2025-12-04T10:47:34.154252Z","shell.execute_reply.started":"2025-12-04T10:47:34.137186Z","shell.execute_reply":"2025-12-04T10:47:34.153298Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df = pd.read_csv(train_csv)\n\ntarget_col = \"LoanApproved\"\n\ndf[target_col] = pd.to_numeric(df[target_col])\ndf = df.dropna(subset=[target_col])\n\ndf = df[np.isfinite(df[target_col])]\n\nif abs_cap is not None:\n    df = df[df[target_col].abs() <= abs_cap]\n\ncat_cols = [\n    \"MaritalStatus\",\n    \"HomeOwnershipStatus\",\n    \"LoanPurpose\",\n    \"EmploymentStatus\",\n    \"EducationLevel\",\n]\n\nX_numeric = df.select_dtypes(include=[np.number]).drop(columns=[target_col])\nX_categorical = df[cat_cols].copy()\n\ny = df[target_col].astype(float).values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.154968Z","iopub.execute_input":"2025-12-04T10:47:34.155164Z","iopub.status.idle":"2025-12-04T10:47:34.214799Z","shell.execute_reply.started":"2025-12-04T10:47:34.155150Z","shell.execute_reply":"2025-12-04T10:47:34.213756Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"X_numeric = X_numeric.replace([np.inf, -np.inf], np.nan).astype(float)\n\nlower_q, upper_q = 0.01, 0.99\nlower_bounds = X_numeric.quantile(lower_q)\nupper_bounds = X_numeric.quantile(upper_q)\n\nX_winsorized = X_numeric.copy()\nfor col in X_winsorized.columns:\n    x = X_winsorized[col].to_numpy(dtype=float, copy=True)\n    lo = lower_bounds.get(col, np.nan)\n    hi = upper_bounds.get(col, np.nan)\n    if np.isfinite(lo):\n        x = np.where(np.isfinite(x), np.maximum(x, lo), x)\n    if np.isfinite(hi):\n        x = np.where(np.isfinite(x), np.minimum(x, hi), x)\n    X_winsorized[col] = x\n\nimputer = SimpleImputer(strategy=\"median\").fit(X_winsorized)\nX_imputed = pd.DataFrame(\n    imputer.transform(X_winsorized),\n    columns=X_winsorized.columns,\n    index=X_winsorized.index,\n)\n\nscaler = StandardScaler().fit(X_imputed)\nX_scaled = pd.DataFrame(\n    scaler.transform(X_imputed),\n    columns=X_imputed.columns,\n    index=X_imputed.index,\n)\n\nX_scaled.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.215808Z","iopub.execute_input":"2025-12-04T10:47:34.216079Z","iopub.status.idle":"2025-12-04T10:47:34.307206Z","shell.execute_reply.started":"2025-12-04T10:47:34.216056Z","shell.execute_reply":"2025-12-04T10:47:34.306783Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        Age  AnnualIncome  CreditScore  LoanAmount  LoanDuration  \\\n0 -1.113466     -0.564809    -0.766337   -0.488753      0.267843   \n1  1.320547      0.369619     0.991736   -0.537888     -0.712053   \n\n   NumberOfDependents  MonthlyDebtPayments  CreditCardUtilizationRate  \\\n0           -0.400618             1.278852                  -0.837264   \n1           -0.400618            -0.727581                  -0.686917   \n\n   NumberOfOpenCreditLines  NumberOfCreditInquiries  ...  TotalLiabilities  \\\n0                -0.596791                 0.024253  ...         -0.412038   \n1                -0.016598                -0.997202  ...          0.027228   \n\n   MonthlyIncome  UtilityBillsPaymentHistory  JobTenure  Experience  NetWorth  \\\n0      -0.561490                    1.017308  -0.439187   -1.210193 -0.342669   \n1       0.373625                    0.102751  -1.364223    1.372561 -0.371166   \n\n   BaseInterestRate  InterestRate  MonthlyLoanPayment  TotalDebtToIncomeRatio  \n0          0.643131      0.543748           -0.491378               -0.291620  \n1         -1.242181     -1.121284           -0.486119               -0.624373  \n\n[2 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>AnnualIncome</th>\n      <th>CreditScore</th>\n      <th>LoanAmount</th>\n      <th>LoanDuration</th>\n      <th>NumberOfDependents</th>\n      <th>MonthlyDebtPayments</th>\n      <th>CreditCardUtilizationRate</th>\n      <th>NumberOfOpenCreditLines</th>\n      <th>NumberOfCreditInquiries</th>\n      <th>...</th>\n      <th>TotalLiabilities</th>\n      <th>MonthlyIncome</th>\n      <th>UtilityBillsPaymentHistory</th>\n      <th>JobTenure</th>\n      <th>Experience</th>\n      <th>NetWorth</th>\n      <th>BaseInterestRate</th>\n      <th>InterestRate</th>\n      <th>MonthlyLoanPayment</th>\n      <th>TotalDebtToIncomeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.113466</td>\n      <td>-0.564809</td>\n      <td>-0.766337</td>\n      <td>-0.488753</td>\n      <td>0.267843</td>\n      <td>-0.400618</td>\n      <td>1.278852</td>\n      <td>-0.837264</td>\n      <td>-0.596791</td>\n      <td>0.024253</td>\n      <td>...</td>\n      <td>-0.412038</td>\n      <td>-0.561490</td>\n      <td>1.017308</td>\n      <td>-0.439187</td>\n      <td>-1.210193</td>\n      <td>-0.342669</td>\n      <td>0.643131</td>\n      <td>0.543748</td>\n      <td>-0.491378</td>\n      <td>-0.291620</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.320547</td>\n      <td>0.369619</td>\n      <td>0.991736</td>\n      <td>-0.537888</td>\n      <td>-0.712053</td>\n      <td>-0.400618</td>\n      <td>-0.727581</td>\n      <td>-0.686917</td>\n      <td>-0.016598</td>\n      <td>-0.997202</td>\n      <td>...</td>\n      <td>0.027228</td>\n      <td>0.373625</td>\n      <td>0.102751</td>\n      <td>-1.364223</td>\n      <td>1.372561</td>\n      <td>-0.371166</td>\n      <td>-1.242181</td>\n      <td>-1.121284</td>\n      <td>-0.486119</td>\n      <td>-0.624373</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"corr_with_target = (\n    X_scaled.assign(target = y)\n    .corr(numeric_only=True)[\"target\"]\n    .drop(\"target\")\n    .abs()\n    .sort_values(ascending=False)\n)\n\ntop_features = corr_with_target.head(min(top_k, len(corr_with_target))).index.tolist()\nbase_features = [c for c in X_scaled.columns if c not in top_features]\n\npoly_transformer = PolynomialFeatures(degree=degree, include_bias=True)\npoly_transformer.fit(X_scaled[top_features])\n\nX_poly = pd.DataFrame(\n    poly_transformer.transform(X_scaled[top_features]),\n    columns=poly_transformer.get_feature_names_out(top_features),\n    index=X_scaled.index,\n)\n\nX_poly.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.308114Z","iopub.execute_input":"2025-12-04T10:47:34.308253Z","iopub.status.idle":"2025-12-04T10:47:34.375361Z","shell.execute_reply.started":"2025-12-04T10:47:34.308241Z","shell.execute_reply":"2025-12-04T10:47:34.374771Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"     1  MonthlyIncome  AnnualIncome  InterestRate  BaseInterestRate  \\\n0  1.0      -0.561490     -0.564809      0.543748          0.643131   \n1  1.0       0.373625      0.369619     -1.121284         -1.242181   \n\n   CreditScore  TotalDebtToIncomeRatio  MonthlyLoanPayment  LoanAmount  \\\n0    -0.766337               -0.291620           -0.491378   -0.488753   \n1     0.991736               -0.624373           -0.486119   -0.537888   \n\n   MonthlyIncome^2  ...  TotalDebtToIncomeRatio^2 LoanAmount^2  \\\n0         0.315271  ...                               0.020315   \n1         0.139596  ...                               0.112791   \n\n   TotalDebtToIncomeRatio MonthlyLoanPayment^3  \\\n0                                     0.034599   \n1                                     0.071725   \n\n   TotalDebtToIncomeRatio MonthlyLoanPayment^2 LoanAmount  \\\n0                                           0.034414        \n1                                           0.079364        \n\n   TotalDebtToIncomeRatio MonthlyLoanPayment LoanAmount^2  \\\n0                                           0.034230        \n1                                           0.087816        \n\n   TotalDebtToIncomeRatio LoanAmount^3  MonthlyLoanPayment^4  \\\n0                             0.034048              0.058299   \n1                             0.097167              0.055843   \n\n   MonthlyLoanPayment^3 LoanAmount  MonthlyLoanPayment^2 LoanAmount^2  \\\n0                         0.057988                           0.057678   \n1                         0.061790                           0.068371   \n\n   MonthlyLoanPayment LoanAmount^3  LoanAmount^4  \n0                         0.057370      0.057063  \n1                         0.075652      0.083708  \n\n[2 rows x 495 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>MonthlyIncome</th>\n      <th>AnnualIncome</th>\n      <th>InterestRate</th>\n      <th>BaseInterestRate</th>\n      <th>CreditScore</th>\n      <th>TotalDebtToIncomeRatio</th>\n      <th>MonthlyLoanPayment</th>\n      <th>LoanAmount</th>\n      <th>MonthlyIncome^2</th>\n      <th>...</th>\n      <th>TotalDebtToIncomeRatio^2 LoanAmount^2</th>\n      <th>TotalDebtToIncomeRatio MonthlyLoanPayment^3</th>\n      <th>TotalDebtToIncomeRatio MonthlyLoanPayment^2 LoanAmount</th>\n      <th>TotalDebtToIncomeRatio MonthlyLoanPayment LoanAmount^2</th>\n      <th>TotalDebtToIncomeRatio LoanAmount^3</th>\n      <th>MonthlyLoanPayment^4</th>\n      <th>MonthlyLoanPayment^3 LoanAmount</th>\n      <th>MonthlyLoanPayment^2 LoanAmount^2</th>\n      <th>MonthlyLoanPayment LoanAmount^3</th>\n      <th>LoanAmount^4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>-0.561490</td>\n      <td>-0.564809</td>\n      <td>0.543748</td>\n      <td>0.643131</td>\n      <td>-0.766337</td>\n      <td>-0.291620</td>\n      <td>-0.491378</td>\n      <td>-0.488753</td>\n      <td>0.315271</td>\n      <td>...</td>\n      <td>0.020315</td>\n      <td>0.034599</td>\n      <td>0.034414</td>\n      <td>0.034230</td>\n      <td>0.034048</td>\n      <td>0.058299</td>\n      <td>0.057988</td>\n      <td>0.057678</td>\n      <td>0.057370</td>\n      <td>0.057063</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.373625</td>\n      <td>0.369619</td>\n      <td>-1.121284</td>\n      <td>-1.242181</td>\n      <td>0.991736</td>\n      <td>-0.624373</td>\n      <td>-0.486119</td>\n      <td>-0.537888</td>\n      <td>0.139596</td>\n      <td>...</td>\n      <td>0.112791</td>\n      <td>0.071725</td>\n      <td>0.079364</td>\n      <td>0.087816</td>\n      <td>0.097167</td>\n      <td>0.055843</td>\n      <td>0.061790</td>\n      <td>0.068371</td>\n      <td>0.075652</td>\n      <td>0.083708</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 495 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"def make_safe(arr, clip_limit=None):\n    arr = np.asarray(arr, dtype=float)\n    arr[~np.isfinite(arr)] = 0.0\n    if clip_limit is not None:\n        arr = np.clip(arr, -clip_limit, clip_limit)\n    return arr\n\nclip_limit = clip_val\nepsilon = eps\n\nfeature_stats = {}\nfor col in top_features:\n    values = X_imputed[col].astype(float).values\n    mean_val = float(np.nanmean(values))\n    std_val = float(np.nanstd(values))\n    feature_stats[col] = (mean_val, std_val if std_val > 0 else epsilon)\n\nfeature_list = list(top_features)\nderived_features = {}\n\nfor col in feature_list:\n    x = X_imputed[col].astype(float).values\n    mean_val, std_val = feature_stats[col]\n    std_val = std_val if std_val > 0 else epsilon\n\n    derived_features[f\"{col}__pow2\"] = make_safe(np.power(x, 2), clip_limit)\n    if degree >= 3:\n        derived_features[f\"{col}__pow3\"] = make_safe(np.power(x, 3), clip_limit)\n    if degree >= 4:\n        derived_features[f\"{col}__pow4\"] = make_safe(np.power(x, 4), clip_limit)\n\n    derived_features[f\"{col}__abs\"] = make_safe(np.abs(x), clip_limit)\n    derived_features[f\"{col}__sqrt\"] = make_safe(np.sqrt(np.clip(x, 0, None)), clip_limit)\n\n    log1p_pos = make_safe(np.log1p(np.clip(x, 0, None)), clip_limit)\n    derived_features[f\"{col}__log1p_pos\"] = log1p_pos\n    derived_features[f\"{col}__slog1p\"] = make_safe(np.sign(x) * np.log1p(np.abs(x)), clip_limit)\n    derived_features[f\"{col}__recip\"] = make_safe(1.0 / (np.where(x == 0.0, epsilon, x)), clip_limit)\n\n    z_score = make_safe((x - mean_val) / (std_val + epsilon), clip_limit)\n    derived_features[f\"{col}__z\"] = z_score\n    centered = make_safe(x - mean_val, clip_limit)\n    derived_features[f\"{col}__ctr\"]  = centered\n    derived_features[f\"{col}__ctr2\"] = make_safe(centered**2, clip_limit)\n    derived_features[f\"{col}__tanh\"] = np.tanh(x / (std_val + epsilon))\n\nfor fa, fb in combinations(feature_list, 2):\n    xa = X_imputed[fa].astype(float).values\n    xb = X_imputed[fb].astype(float).values\n\n    za = derived_features[f\"{fa}__z\"]\n    zb = derived_features[f\"{fb}__z\"]\n\n    derived_features[f\"{fa}__x__{fb}\"] = make_safe(xa * xb, clip_limit)\n    derived_features[f\"{fa}__plus__{fb}\"] = make_safe(xa + xb, clip_limit)\n    derived_features[f\"{fa}__minus__{fb}\"] = make_safe(xa - xb, clip_limit)\n    derived_features[f\"{fb}__minus__{fa}\"] = make_safe(xb - xa, clip_limit)\n    derived_features[f\"{fa}__div__{fb}\"] = make_safe(xa / (np.where(xb == 0.0, epsilon, xb)), clip_limit)\n    derived_features[f\"{fb}__div__{fa}\"] = make_safe(xb / (np.where(xa == 0.0, epsilon, xa)), clip_limit)\n\n    derived_features[f\"{fa}__z_x__{fb}__z\"] = make_safe(za * zb, clip_limit)\n    derived_features[f\"{fa}__z_div__{fb}__z_tanh\"] = np.tanh(za / (np.abs(zb) + epsilon))\n    derived_features[f\"{fa}__rel_diff__{fb}\"] = make_safe((xa - xb) / (np.abs(xa) + np.abs(xb) + epsilon), 1.0)\n    derived_features[f\"{fa}__min__{fb}\"] = np.minimum(xa, xb)\n    derived_features[f\"{fa}__max__{fb}\"] = np.maximum(xa, xb)\n\n    la = derived_features[f\"{fa}__log1p_pos\"]\n    lb = derived_features[f\"{fb}__log1p_pos\"]\n    derived_features[f\"{fa}__log_x__{fb}__log\"] = make_safe(la * lb, clip_limit)\n\n    pa = np.clip(xa, 0, None)\n    pb = np.clip(xb, 0, None)\n    derived_features[f\"{fa}__gmean__{fb}\"] = make_safe(np.sqrt(pa * pb), clip_limit)\n    derived_features[f\"{fa}__hmean__{fb}\"] = make_safe(2.0 * pa * pb / (pa + pb + epsilon), clip_limit)\n\n    derived_features[f\"{fa}2__x__{fb}__z\"] = make_safe((za * za) * zb, clip_limit)\n    derived_features[f\"{fa}__x__{fb}2__z\"] = make_safe(za * (zb * zb), clip_limit)\n\nderived_df = pd.DataFrame(derived_features, index=X_imputed.index)\nderived_cols = derived_df.columns.tolist()\n\nderived_scaler = StandardScaler().fit(derived_df)\nderived_scaled = pd.DataFrame(\n    derived_scaler.transform(derived_df),\n    columns=derived_cols,\n    index=derived_df.index\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.380279Z","iopub.execute_input":"2025-12-04T10:47:34.381227Z","iopub.status.idle":"2025-12-04T10:47:34.521290Z","shell.execute_reply.started":"2025-12-04T10:47:34.381194Z","shell.execute_reply":"2025-12-04T10:47:34.520308Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import (\n    roc_auc_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    average_precision_score\n)\nfrom sklearn.model_selection import GridSearchCV\n\nohe_train = pd.get_dummies(X_categorical, drop_first=True)\nohe_cols = ohe_train.columns.tolist()\n\ndesign_X = pd.concat(\n    [\n        X_scaled[base_features].reset_index(drop=True),\n        X_poly.reset_index(drop=True),\n        derived_scaled.reset_index(drop=True),\n        ohe_train.reset_index(drop=True),\n    ],\n    axis=1\n)\n\nridge = Ridge(random_state=42)\n\nparam_grid = {\n    \"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n}\n\ngrid_search = GridSearchCV(\n    estimator=ridge,\n    param_grid=param_grid,\n    scoring=\"roc_auc\",  \n    cv=5,\n    n_jobs=-1,\n    verbose=1\n)\n\ngrid_search.fit(design_X, y)\n\nprint(\"Лучшие параметры:\", grid_search.best_params_)\nprint(f\"Лучший ROC-AUC (CV): {grid_search.best_score_:.6f}\")\n\nbest_model = grid_search.best_estimator_\n\ny_scores = best_model.predict(design_X)\n\ny_proba = np.clip(y_scores, 0.0, 1.0)\n\ny_pred = (y_proba >= 0.5).astype(int)\n\nroc_auc = roc_auc_score(y, y_proba)\npr_auc = average_precision_score(y, y_proba) \nprecision = precision_score(y, y_pred, zero_division=0)\nrecall = recall_score(y, y_pred, zero_division=0)\nf1 = f1_score(y, y_pred, zero_division=0)\n\nprint(f\"ROC-AUC: {roc_auc:.6f}\")\nprint(f\"PR-AUC: {pr_auc:.6f}\")\nprint(f\"Precision: {precision:.6f}\")\nprint(f\"Recall: {recall:.6f}\")\nprint(f\"F1-score: {f1:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:34.523021Z","iopub.execute_input":"2025-12-04T10:47:34.523286Z","iopub.status.idle":"2025-12-04T10:47:42.516750Z","shell.execute_reply.started":"2025-12-04T10:47:34.523263Z","shell.execute_reply":"2025-12-04T10:47:42.516179Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 8 candidates, totalling 40 fits\nЛучшие параметры: {'alpha': 100.0}\nЛучший ROC-AUC (CV): 0.980005\nROC-AUC: 0.982617\nPR-AUC: 0.984045\nPrecision: 0.928301\nRecall: 0.914291\nF1-score: 0.921243\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"df_test = pd.read_csv(test_csv)\n\nX_numeric_test = df_test.select_dtypes(include=[np.number]).reindex(columns=X_numeric.columns)\nX_categorical_test = df_test[cat_cols].copy()\n\nX_numeric_test = X_numeric_test.replace([np.inf, -np.inf], np.nan).astype(float)\n\nX_winsorized_test = X_numeric_test.copy()\nfor col in X_winsorized_test.columns:\n    x = X_winsorized_test[col].to_numpy(dtype=float, copy=True)\n    lo = lower_bounds.get(col, np.nan)\n    hi = upper_bounds.get(col, np.nan)\n    if np.isfinite(lo):\n        x = np.where(np.isfinite(x), np.maximum(x, lo), x)\n    if np.isfinite(hi):\n        x = np.where(np.isfinite(x), np.minimum(x, hi), x)\n    X_winsorized_test[col] = x\n\nX_imputed_test = pd.DataFrame(\n    imputer.transform(X_winsorized_test),\n    columns = X_winsorized_test.columns,\n    index = X_winsorized_test.index,\n)\n\nX_scaled_test = pd.DataFrame(\n    scaler.transform(X_imputed_test),\n    columns = X_imputed_test.columns,\n    index = X_imputed_test.index,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:42.517170Z","iopub.execute_input":"2025-12-04T10:47:42.517326Z","iopub.status.idle":"2025-12-04T10:47:42.558441Z","shell.execute_reply.started":"2025-12-04T10:47:42.517312Z","shell.execute_reply":"2025-12-04T10:47:42.557744Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"X_poly_test = pd.DataFrame(\n    poly_transformer.transform(X_scaled_test[top_features]),\n    columns=poly_transformer.get_feature_names_out(top_features),\n    index=X_scaled_test.index,\n)\n\nfeature_list = list(top_features)\nderived_test = {}\n\nfor col in feature_list:\n    x = X_imputed_test[col].astype(float).values\n    mean_val, std_val = feature_stats[col]\n    std_val = std_val if std_val > 0 else epsilon\n\n    derived_test[f\"{col}__pow2\"] = make_safe(np.power(x, 2), clip_limit)\n    if degree >= 3:\n        derived_test[f\"{col}__pow3\"] = make_safe(np.power(x, 3), clip_limit)\n    if degree >= 4:\n        derived_test[f\"{col}__pow4\"] = make_safe(np.power(x, 4), clip_limit)\n\n    derived_test[f\"{col}__abs\"] = make_safe(np.abs(x), clip_limit)\n    derived_test[f\"{col}__sqrt\"] = make_safe(np.sqrt(np.clip(x, 0, None)), clip_limit)\n\n    log1p_pos = make_safe(np.log1p(np.clip(x, 0, None)), clip_limit)\n    derived_test[f\"{col}__log1p_pos\"] = log1p_pos\n    derived_test[f\"{col}__slog1p\"] = make_safe(np.sign(x) * np.log1p(np.abs(x)), clip_limit)\n    derived_test[f\"{col}__recip\"] = make_safe(1.0 / (np.where(x == 0.0, epsilon, x)), clip_limit)\n\n    z_score = make_safe((x - mean_val) / (std_val + epsilon), clip_limit)\n    derived_test[f\"{col}__z\"] = z_score\n    centered = make_safe(x - mean_val, clip_limit)\n    derived_test[f\"{col}__ctr\"] = centered\n    derived_test[f\"{col}__ctr2\"] = make_safe(centered**2, clip_limit)\n    derived_test[f\"{col}__tanh\"] = np.tanh(x / (std_val + epsilon))\n\nfor fa, fb in combinations(feature_list, 2):\n    xa = X_imputed_test[fa].astype(float).values\n    xb = X_imputed_test[fb].astype(float).values\n\n    za = derived_test[f\"{fa}__z\"]\n    zb = derived_test[f\"{fb}__z\"]\n\n    derived_test[f\"{fa}__x__{fb}\"] = make_safe(xa * xb, clip_limit)\n    derived_test[f\"{fa}__plus__{fb}\"] = make_safe(xa + xb, clip_limit)\n    derived_test[f\"{fa}__minus__{fb}\"] = make_safe(xa - xb, clip_limit)\n    derived_test[f\"{fb}__minus__{fa}\"] = make_safe(xb - xa, clip_limit)\n    derived_test[f\"{fa}__div__{fb}\"] = make_safe(xa / (np.where(xb == 0.0, epsilon, xb)), clip_limit)\n    derived_test[f\"{fb}__div__{fa}\"] = make_safe(xb / (np.where(xa == 0.0, epsilon, xa)), clip_limit)\n\n    derived_test[f\"{fa}__z_x__{fb}__z\"] = make_safe(za * zb, clip_limit)\n    derived_test[f\"{fa}__z_div__{fb}__z_tanh\"] = np.tanh(za / (np.abs(zb) + epsilon))\n    derived_test[f\"{fa}__rel_diff__{fb}\"] = make_safe((xa - xb) / (np.abs(xa) + np.abs(xb) + epsilon), 1.0)\n    derived_test[f\"{fa}__min__{fb}\"] = np.minimum(xa, xb)\n    derived_test[f\"{fa}__max__{fb}\"] = np.maximum(xa, xb)\n\n    la = derived_test[f\"{fa}__log1p_pos\"]\n    lb = derived_test[f\"{fb}__log1p_pos\"]\n    derived_test[f\"{fa}__log_x__{fb}__log\"] = make_safe(la * lb, clip_limit)\n\n    pa = np.clip(xa, 0, None)\n    pb = np.clip(xb, 0, None)\n    derived_test[f\"{fa}__gmean__{fb}\"] = make_safe(np.sqrt(pa * pb), clip_limit)\n    derived_test[f\"{fa}__hmean__{fb}\"] = make_safe(2.0 * pa * pb / (pa + pb + epsilon), clip_limit)\n\n    derived_test[f\"{fa}2__x__{fb}__z\"] = make_safe((za * za) * zb, clip_limit)\n    derived_test[f\"{fa}__x__{fb}2__z\"] = make_safe(za * (zb * zb), clip_limit)\n\nderived_test_df = pd.DataFrame(derived_test, index = X_imputed_test.index).reindex(columns = derived_cols, fill_value = 0.0)\nderived_test_scaled = pd.DataFrame(\n    derived_scaler.transform(derived_test_df),\n    columns = derived_cols,\n    index = derived_test_df.index,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:42.559617Z","iopub.execute_input":"2025-12-04T10:47:42.559974Z","iopub.status.idle":"2025-12-04T10:47:42.639687Z","shell.execute_reply.started":"2025-12-04T10:47:42.559952Z","shell.execute_reply":"2025-12-04T10:47:42.638966Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nalpha_final = 100.0 \n\nridge_final = Ridge(alpha=alpha_final, random_state=42)\nridge_final.fit(design_X, y)\n\nohe_test = pd.get_dummies(X_categorical_test, drop_first=True).reindex(columns=ohe_cols, fill_value=0)\n\ndesign_X_test = pd.concat(\n    [\n        X_scaled_test[base_features].reset_index(drop=True),\n        X_poly_test.reset_index(drop=True),\n        derived_test_scaled.reset_index(drop=True),\n        ohe_test.reset_index(drop=True),\n    ],\n    axis=1\n)\n\ny_pred_test_scores = ridge_final.predict(design_X_test)\n\ny_pred_test = np.clip(y_pred_test_scores, 0.0, 1.0)\n\nsubmission = pd.DataFrame({\"prediction\": y_pred_test})\n\nif \"ID\" in df_test.columns:\n    submission.insert(0, \"ID\", df_test[\"ID\"].values)\n\nsubmission.to_csv(\"predictions.csv\", index=False)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:47:42.640739Z","iopub.execute_input":"2025-12-04T10:47:42.640933Z","iopub.status.idle":"2025-12-04T10:47:43.019750Z","shell.execute_reply.started":"2025-12-04T10:47:42.640916Z","shell.execute_reply":"2025-12-04T10:47:43.019213Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   ID  prediction\n0   0    0.948366\n1   1    0.047680\n2   2    0.967371\n3   3    1.000000\n4   4    1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.948366</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.047680</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.967371</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27}]}